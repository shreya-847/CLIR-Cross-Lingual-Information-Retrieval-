{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etKrzFB2kptw"
      },
      "source": [
        "### Install sentence transformers library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTlHrOwRkxA0",
        "outputId": "8f317f19-f649-4b8b-aec7-6173418abad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/e2/84d6acfcee2d83164149778a33b6bdd1a74e1bcb59b2b2cd1b861359b339/sentence-transformers-0.4.1.2.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.4MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.7.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 31.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.8)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 48.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.4.1.2-cp36-none-any.whl size=103068 sha256=a37865dc327e71ad247767b601dce237c89023f053884af07c64bf67e6d90799\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/33/d1/5703dd56199c09d4a1b41e0c07fb4e7765a84d787cbdc48ac3\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=1a4285823f064643bf3cf85cdd1338285f477ca169955113bdcb1f658696ef92\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers, sentencepiece, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-0.4.1.2 sentencepiece-0.1.95 tokenizers-0.9.4 transformers-4.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-UkyvR9egcs"
      },
      "source": [
        "### Useful imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yhr83nwuejYo",
        "outputId": "974acbce-c119-4786-841d-bc2f57d20ad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import json,glob,nltk,copy,torch,time,sentence_transformers,pickle\n",
        "import numpy as np\n",
        "from scipy import spatial\n",
        "from queue import PriorityQueue\n",
        "from sentence_transformers import SentenceTransformer,util\n",
        "nltk.download('punkt')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ct20dwbsmhb"
      },
      "source": [
        "### Retrieve dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rmi5RJRibuG",
        "outputId": "df7f5161-b88f-43b0-83bb-04a1a8275d19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-02-03 15:16:42--  https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/historical_releases/cord-19_2020-03-13.tar.gz\n",
            "Resolving ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com (ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com)... 52.218.234.233\n",
            "Connecting to ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com (ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com)|52.218.234.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 278921140 (266M) [application/x-tar]\n",
            "Saving to: ‘cord-19_2020-03-13.tar.gz’\n",
            "\n",
            "cord-19_2020-03-13. 100%[===================>] 266.00M  61.7MB/s    in 4.6s    \n",
            "\n",
            "2021-02-03 15:16:47 (57.9 MB/s) - ‘cord-19_2020-03-13.tar.gz’ saved [278921140/278921140]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/historical_releases/cord-19_2020-03-13.tar.gz\n",
        "!tar -xf cord-19_2020-03-13.tar.gz\n",
        "!tar -xf 2020-03-13/comm_use_subset.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsWRMwlR6DwQ"
      },
      "source": [
        "### Prepare GPU Cuda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN25lAzQ6Jws",
        "outputId": "dca16130-2dd4-41c7-f865-48ef64e7f892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device available for running: \n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device available for running: \")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i798G_ziUFqQ"
      },
      "source": [
        "### Read JSON files and store title,abstract and text of each article into a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kfpcKOZ-a6S"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "\n",
        "files = glob.glob('comm_use_subset/*', recursive=True)\n",
        "number_of_articles = len(files)\n",
        "bound = 9000\n",
        "\n",
        "for single_file in files[0:bound]:\n",
        "  with open(single_file, 'r') as f:\n",
        "    json_file = json.load(f)\n",
        "\n",
        "    # Retrieve title\n",
        "    title = json_file[\"metadata\"][\"title\"]\n",
        "\n",
        "    # Retrieve abstracts\n",
        "    abstracts = []\n",
        "    if len(json_file[\"abstract\"]) != 0 :\n",
        "      for abstract in json_file[\"abstract\"]:\n",
        "        abstracts.append(abstract[\"text\"])\n",
        "\n",
        "    # Retrieve texts\n",
        "    texts = []\n",
        "    for text in json_file[\"body_text\"]:\n",
        "      texts.append(text[\"text\"])\n",
        "\n",
        "    data.append([title,abstracts,texts])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYl7u849jyJ2"
      },
      "source": [
        "### Convert corpus to sentences with help of library nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IY127-hMhn98"
      },
      "outputs": [],
      "source": [
        "# For each article\n",
        "for article in range(bound):\n",
        "\n",
        "  # Abstracts section\n",
        "  for abstract in range(len(data[article][1])):\n",
        "    data[article][1][abstract] = nltk.sent_tokenize(data[article][1][abstract])\n",
        "\n",
        "  # Texts section\n",
        "  for text in range(len(data[article][2])):\n",
        "    data[article][2][text] = nltk.sent_tokenize(data[article][2][text])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv3dZmeDoJIE"
      },
      "source": [
        "### Transform sentences to embeddings with first sentence trasformer 'stsb-bert-base' model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtobtUXBEAda",
        "outputId": "cf56da09-bcd2-4257-ab35-11d6751718ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed time: 110.3 minutes\n"
          ]
        }
      ],
      "source": [
        "# We gonna calculate time spent for sentence embeddings\n",
        "fist_start_time = time.time()\n",
        "\n",
        "# Declare our first sentence transformer model and pass it to appropriate device\n",
        "first_model = SentenceTransformer('stsb-bert-base').to(device)\n",
        "\n",
        "# Here we'll put sentence embeddings of each article from first sentence transformer model\n",
        "first_sentence_embeddings = [[] for i in range(bound)]\n",
        "\n",
        "# Here we'll put for each article sentences of abstract and body text\n",
        "flatten_data = [[] for i in range(bound)]\n",
        "\n",
        "# For each article\n",
        "for article in range(bound):\n",
        "\n",
        "  # Get abstract and body text of each article\n",
        "  abstract_ = data[article][1]\n",
        "  body_ = data[article][2]\n",
        "\n",
        "  # Process to keep abstract and body text's sentences of each article in a big list\n",
        "  for abstract in abstract_:\n",
        "    for sentence in abstract:\n",
        "      flatten_data[article].append(sentence)\n",
        "  for text in body_:\n",
        "    for sentence in text:\n",
        "      flatten_data[article].append(sentence)\n",
        "\n",
        "  # Transform sentences to embeddings\n",
        "  first_sentence_embeddings[article].append(first_model.encode(flatten_data[article],convert_to_tensor=True))\n",
        "\n",
        "  # Convert all sentence embeddings to a 2D pytorch tensor\n",
        "  first_sentence_embeddings[article] = torch.cat(first_sentence_embeddings[article])\n",
        "\n",
        "# Check elapsed time of first model\n",
        "first_model_time = (time.time() - fist_start_time)/60\n",
        "print(\"Elapsed time: %s minutes\" % (round(first_model_time,1)))\n",
        "\n",
        "# # Save first sentence embeddings\n",
        "# with open('/content/drive/MyDrive/first_sentence_embeddings.pkl', 'wb') as f:\n",
        "#   pickle.dump(first_sentence_embeddings,f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luXB8zb2ujm9"
      },
      "source": [
        "### Random printings just for safety reasons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAPejYmjgGbN",
        "outputId": "fdebc945-2163-4ed8-d71f-cbebbc099592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9000 <class 'list'>\n",
            "140 <class 'torch.Tensor'>\n",
            "torch.Size([140, 768])\n",
            "9000 <class 'list'>\n",
            "140 <class 'list'>\n",
            "150 <class 'str'>\n",
            "The essential requirement of the lymphotoxin beta receptor (LTβR) in the development and maintenance of peripheral lymphoid organs is well recognized.\n"
          ]
        }
      ],
      "source": [
        "# Testing with prints\n",
        "print(len(first_sentence_embeddings),type(first_sentence_embeddings))\n",
        "print(len(first_sentence_embeddings[0]),type(first_sentence_embeddings[0]))\n",
        "print(first_sentence_embeddings[0].shape)\n",
        "\n",
        "print(len(flatten_data),type(flatten_data))\n",
        "print(len(flatten_data[0]),type(flatten_data[0]))\n",
        "print(len(flatten_data[0][0]),type(flatten_data[0][0]))\n",
        "print(flatten_data[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N9sewtpXLxz"
      },
      "source": [
        "### Declare our queries and tranform them to embeddings based on our two models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWl9zu5ix4hO",
        "outputId": "10f14f8e-8f4a-4c08-d221-95e5b8296f07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For 1st model... Number Of Queries: 8  Query Embedding's Length: 768\n"
          ]
        }
      ],
      "source": [
        "queries = ['What are the coronoviruses?','What was discovered in Wuhuan in December 2019?',\n",
        "           'What is Coronovirus Disease 2019?','What is COVID-19?','What is caused by SARS-COV2?',\n",
        "           'How is COVID-19 spread?','Where was COVID-19 discovered?','How does coronavirus spread?']\n",
        "\n",
        "first_queries_embeddings = first_model.encode(queries,convert_to_tensor=True)\n",
        "\n",
        "print(\"For 1st model... Number Of Queries:\",len(first_queries_embeddings),\" Query Embedding's Length:\",len(first_queries_embeddings[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCJRyPRTYa_P"
      },
      "source": [
        "### Test our first model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn_G7bde1YNB",
        "outputId": "3048c1fc-90f1-418e-ce85-2131bf070cf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: What are the coronoviruses? \n",
            "\n",
            "Answer 1 : in orthomyxoviruses (e.g. \n",
            "From article: Mapping overlapping functional elements embedded within the protein-coding regions of RNA viruses \n",
            "Score: 0.7579688 \n",
            "\n",
            "Answer 2 : C) Parechoviruses. \n",
            "From article: A viral metagenomic survey identifies known and novel mammalian viruses in bats from Saudi Arabia \n",
            "Score: 0.7296622 \n",
            "\n",
            "Answer 3 : reoviruses and orthomyxoviruses). \n",
            "From article: Non-canonical translation in RNA viruses \n",
            "Score: 0.6961699 \n",
            "\n",
            "Answer 4 : Adenoviruses. \n",
            "From article: Virus-induced exacerbations in asthma and COPD \n",
            "Score: 0.6928731 \n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------\n",
            "Query: What was discovered in Wuhuan in December 2019? \n",
            "\n",
            "Answer 1 : In December 2019 \n",
            "From article: Clinical Medicine Characteristics of and Public Health Responses to the Coronavirus Disease 2019 Outbreak in China \n",
            "Score: 0.7151003 \n",
            "\n",
            "Answer 2 : (2019c) , Zhao et al. \n",
            "From article: Distributed under Creative Commons CC-BY 4.0 Modelling the effective reproduction number of vector-borne diseases: the yellow fever outbreak in Luanda, Angola 2015-2016 as an example \n",
            "Score: 0.69906324 \n",
            "\n",
            "Answer 3 : 2019; Li et al. \n",
            "From article: Preparation and characterization of a single-domain antibody specific for the porcine epidemic diarrhea virus spike protein \n",
            "Score: 0.69682556 \n",
            "\n",
            "Answer 4 : WHO are referring to it as '2019-nCov'. \n",
            "From article: President, World Organisation of Family Doctors (WONca) \n",
            "Score: 0.63965595 \n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------\n",
            "Query: What is Coronovirus Disease 2019? \n",
            "\n",
            "Answer 1 : The spectrum of this disease in humans, now named coronavirus disease 2019 (COVID-19) [5] , is yet to be fully determined. \n",
            "From article: Rapid communication \n",
            "Score: 0.62452435 \n",
            "\n",
            "Answer 2 : Vaccines 2019, 7, 173 2 of 12 the CV777 vaccine strain belonging to subtype G1 [11] . \n",
            "From article: Significant Interference with Porcine Epidemic Diarrhea Virus Pandemic and Classical Strain Replication in Small-Intestine Epithelial Cells Using an shRNA Expression Vector \n",
            "Score: 0.6191194 \n",
            "\n",
            "Answer 3 : The 2019 novel coronavirus (2019-nCoV), a betacoronavirus, forms a clade within the subgenus sarbecovirus of the Orthocoronavirinae subfamily [4] . \n",
            "From article: Potential Rapid Diagnostics, Vaccine and Therapeutics for 2019 Novel Coronavirus (2019-nCoV): A Systematic Review \n",
            "Score: 0.6055144 \n",
            "\n",
            "Answer 4 : The disease caused by SARS-CoV-2 was called \"coronavirus disease 2019\" (COVID-19) [7] . \n",
            "From article: Systematic Comparison of Two Animal-to-Human Transmitted Human Coronaviruses: SARS-CoV-2 and SARS-CoV \n",
            "Score: 0.60359573 \n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------\n",
            "Query: What is COVID-19? \n",
            "\n",
            "Answer 1 : The main dataset of this study is COVID-19 dataset. \n",
            "From article: Clinical Medicine Optimization Method for Forecasting Confirmed Cases of COVID-19 in China \n",
            "Score: 0.65359545 \n",
            "\n",
            "Answer 2 : It remains to be seen if this will be the case for COVID-19 as well. \n",
            "From article: Clinical Medicine Incubation Period and Other Epidemiological Characteristics of 2019 Novel Coronavirus Infections with Right Truncation: A Statistical Analysis of Publicly Available Case Data \n",
            "Score: 0.62117475 \n",
            "\n",
            "Answer 3 : (19) <ii>. \n",
            "From article: Enteropathogen co-infection in UK cats with diarrhoea \n",
            "Score: 0.6208621 \n",
            "\n",
            "Answer 4 : This is particularly true for the COVID-19. \n",
            "From article: First two months of the 2019 Coronavirus Disease (COVID-19) epidemic in China: real- time surveillance and evaluation with a second derivative model \n",
            "Score: 0.60347044 \n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------\n",
            "Query: What is caused by SARS-COV2? \n",
            "\n",
            "Answer 1 : Epidemiology of SARS-CoV and MERS-CoV \n",
            "From article: viruses Review From SARS to MERS, Thrusting Coronaviruses into the Spotlight \n",
            "Score: 0.67696023 \n",
            "\n",
            "Answer 2 : produced by SARS-CoV-infected cells, or whether it is a secondary effect, i.e. \n",
            "From article: Virology Journal Inhibition of cytokine gene expression and induction of chemokine genes in non-lymphatic cells infected with SARS coronavirus \n",
            "Score: 0.6758429 \n",
            "\n",
            "Answer 3 : Is there an effective specific anti-SARS-CoV-2 solution? \n",
            "From article: Systematic Comparison of Two Animal-to-Human Transmitted Human Coronaviruses: SARS-CoV-2 and SARS-CoV \n",
            "Score: 0.6730329 \n",
            "\n",
            "Answer 4 : If indeed so, could this then indicate a probable basis for the increased pathogenicity of SARS-CoV compared to HCoV-NL63? \n",
            "From article: The Coronavirus Nucleocapsid Is a Multifunctional Protein \n",
            "Score: 0.6687777 \n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------\n",
            "Query: How is COVID-19 spread? \n",
            "\n",
            "Answer 1 : It is a time series method for forecasting the confirmed cases of the COVID-19, as given in Figure 2 . \n",
            "From article: Clinical Medicine Optimization Method for Forecasting Confirmed Cases of COVID-19 in China \n",
            "Score: 0.6681634 \n",
            "\n",
            "Answer 2 : The screening of the D. pulex genome database suggests 19 loci with VTG-like coding sequences. \n",
            "From article: Acclimatory responses of the Daphnia pulex proteome to environmental changes. II. Chronic exposure to different temperatures (10 and 20°C) mainly affects protein metabolism \n",
            "Score: 0.6484313 \n",
            "\n",
            "Answer 3 : The value of the basic reproduction number R 0 for the COVID-19 epidemic was calculated as \n",
            "From article: Clinical Medicine Real-Time Estimation of the Risk of Death from Novel Coronavirus (COVID-19) Infection: Inference Using Exported Cases \n",
            "Score: 0.62284505 \n",
            "\n",
            "Answer 4 : First, we compared the density of synonymous and nonsynonymous generegion SNPs in CEACAM/PSG genes to those of other genes on chromosome 19. \n",
            "From article: Widespread Divergence of the CEACAM/PSG Genes in Vertebrates and Humans Suggests Sensitivity to Selection \n",
            "Score: 0.6133218 \n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------\n",
            "Query: Where was COVID-19 discovered? \n",
            "\n",
            "Answer 1 : It is a time series method for forecasting the confirmed cases of the COVID-19, as given in Figure 2 . \n",
            "From article: Clinical Medicine Optimization Method for Forecasting Confirmed Cases of COVID-19 in China \n",
            "Score: 0.6720117 \n",
            "\n",
            "Answer 2 : The value of the basic reproduction number R 0 for the COVID-19 epidemic was calculated as \n",
            "From article: Clinical Medicine Real-Time Estimation of the Risk of Death from Novel Coronavirus (COVID-19) Infection: Inference Using Exported Cases \n",
            "Score: 0.62296945 \n",
            "\n",
            "Answer 3 : It remains to be seen if this will be the case for COVID-19 as well. \n",
            "From article: Clinical Medicine Incubation Period and Other Epidemiological Characteristics of 2019 Novel Coronavirus Infections with Right Truncation: A Statistical Analysis of Publicly Available Case Data \n",
            "Score: 0.6046771 \n",
            "\n",
            "Answer 4 : The screening of the D. pulex genome database suggests 19 loci with VTG-like coding sequences. \n",
            "From article: Acclimatory responses of the Daphnia pulex proteome to environmental changes. II. Chronic exposure to different temperatures (10 and 20°C) mainly affects protein metabolism \n",
            "Score: 0.6042676 \n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------\n",
            "Query: How does coronavirus spread? \n",
            "\n",
            "Answer 1 : Coronaviruses: what are they? \n",
            "From article: Revisiting the dangers of the coronavirus in the ophthalmology practice \n",
            "Score: 0.82212365 \n",
            "\n",
            "Answer 2 : Coronavirus. \n",
            "From article: Lactobacillus Mucosal Vaccine Vectors: Immune Responses against Bacterial and Viral Antigens \n",
            "Score: 0.7552244 \n",
            "\n",
            "Answer 3 : coronavirus. \n",
            "From article: Tropical Medicine and Infectious Disease Potential Intermediate Hosts for Coronavirus Transmission: No Evidence of Clade 2c Coronaviruses in Domestic Livestock from Ghana \n",
            "Score: 0.75522435 \n",
            "\n",
            "Answer 4 : Coronavirus. \n",
            "From article: Population genetics, community of parasites, and resistance to rodenticides in an urban brown rat (Rattus norvegicus) population \n",
            "Score: 0.75522435 \n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------\n",
            "Elapsed time: 0.8 minutes\n"
          ]
        }
      ],
      "source": [
        "# # Load first sentence embeddings\n",
        "# with open('/content/drive/MyDrive/first_sentence_embeddings.pkl', 'rb') as f:\n",
        "#   first_sentence_embeddings = pickle.load(f)\n",
        "\n",
        "# We gonna calculate time spent for finding best answer\n",
        "fist_start_time = time.time()\n",
        "\n",
        "# For each query\n",
        "for qindex,query in enumerate(first_queries_embeddings):\n",
        "  # Declare an empty priority queue\n",
        "  answer_pq = PriorityQueue()\n",
        "  # For each article's sentence embedding\n",
        "  for index,embed in enumerate(first_sentence_embeddings):\n",
        "    # Find the most similar vector and return it so as to add it to priority queue\n",
        "    first_results = sentence_transformers.util.semantic_search(query,embed,top_k=1)\n",
        "    for res in first_results:\n",
        "      # Add to priority queue triple value of (score,article's index,sentence's index)\n",
        "      answer_pq.put((-res[0]['score'],index,res[0]['corpus_id']))\n",
        "  # Get vectors with the best cosine similarity (which are our answers)\n",
        "  print(\"Query:\",queries[qindex],\"\\n\")\n",
        "  for idx in range(4):\n",
        "    res = answer_pq.get()\n",
        "    print(\"Answer\",idx+1,\":\",flatten_data[res[1]][res[2]],\"\\nFrom article:\",data[res[1]][0],\"\\nScore:\",-res[0],\"\\n\")\n",
        "  print(\"------------------------------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "first_model_time = (time.time() - fist_start_time)/60\n",
        "print(\"Elapsed time: %s minutes\" % (round(first_model_time,1)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Task_1,2_a.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}